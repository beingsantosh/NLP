{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vector = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "file = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "counter =0\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    glove_vector[word] = vectors\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(glove_vector['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vector.get('the').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping tweet id and author columns\n",
    "df=df.drop(columns=['tweet_id','author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    40000 non-null object\n",
      "content      40000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all entries with empty emotions\n",
    "df=df.drop(index=df[df['sentiment']=='empty'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39173 entries, 1 to 39999\n",
      "Data columns (total 2 columns):\n",
      "sentiment    39173 non-null object\n",
      "content      39173 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 918.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "def contraction_(x):\n",
    "    for cont , exp in contraction_mapping.items():\n",
    "        x = re.sub(cont,exp,x)\n",
    "    return x\n",
    "\n",
    "import unicodedata\n",
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return x\n",
    "\n",
    "#email\n",
    "regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def convert_to_root(x):\n",
    "    doc= nlp(x)\n",
    "    x_list=[]\n",
    "    for w in doc:\n",
    "        root = w.lemma_\n",
    "        x_list.append(root)\n",
    "    return ' '.join(x_list)\n",
    "\n",
    "\n",
    "df['content']=df['content'].apply(lambda x: x.lower() )\n",
    "df['content']=df['content'].apply(lambda x: contraction_(x))\n",
    "df['content']=df['content'].apply(lambda x : re.sub('[a-zA-Z0-9_-]*@[a-zA-Z0-9_-]+\\.com',' ', x))\n",
    "df['content']=df['content'].apply(lambda x : re.sub(regex, '', x))\n",
    "df['content']=df['content'].apply(lambda x : re.sub('[^\\w ]+','',x))\n",
    "df['content']=df['content'].apply(lambda x : re.sub('\\s{2,}',' ',x))\n",
    "df['content']=df['content'].apply(lambda x : BeautifulSoup(x,'html').get_text().strip())\n",
    "df['content']=df['content'].apply(lambda x : remove_accented_chars(x))\n",
    "df['content']=df['content'].apply(lambda x : ' '.join([w for w in x.split() if w not in stopwords]))\n",
    "df['content']=df['content'].apply(lambda x : convert_to_root(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughhhhwaitin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo want trade houston ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>worry</td>\n",
       "      <td>reping ghostridah14 prom bc bf like friend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                     content\n",
       "1     sadness           layin n bed headache ughhhhwaitin\n",
       "2     sadness               funeral ceremonygloomy friday\n",
       "3  enthusiasm                       want hang friend soon\n",
       "4     neutral     dannycastillo want trade houston ticket\n",
       "5       worry  reping ghostridah14 prom bc bf like friend"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the blank text from content\n",
    "df = df.drop(index = df[df['content']==''].index, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8619\n",
       "worry         8453\n",
       "happiness     5208\n",
       "sadness       5162\n",
       "love          3842\n",
       "surprise      2182\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1321\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying glove vector on text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 100\n",
    "\n",
    "def get_vec(x):\n",
    "    arr = np.zeros(vector_length)\n",
    "    text= str(x).split()\n",
    "    \n",
    "    for w in text:\n",
    "        try:\n",
    "            vec = glove_vector.get(w).astype(float)\n",
    "            arr = arr + vec\n",
    "        except:\n",
    "            pass\n",
    "    arr = arr.reshape(1,-1)[0]\n",
    "    return arr/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.06160333e-01,  3.79729667e-01,  5.02600000e-02, -2.21787510e-01,\n",
       "       -7.64673333e-01,  5.63833333e-01, -1.71110000e-02,  4.68336667e-01,\n",
       "       -1.43153333e-01, -4.64700000e-02,  8.79586667e-01,  2.41913333e-01,\n",
       "        2.14198733e-01,  3.37680000e-02, -2.37706667e-01, -5.82683333e-01,\n",
       "       -2.25994000e-01,  7.21100000e-02, -4.59583333e-01,  5.85183333e-01,\n",
       "        7.13303333e-02,  8.28140000e-01, -2.83019333e-01, -5.86913333e-01,\n",
       "        4.52246667e-01,  4.47796667e-01,  2.17990000e-01, -4.84950000e-01,\n",
       "        4.80930000e-01, -1.13000000e-03, -3.76493333e-01,  8.69603333e-01,\n",
       "        2.30863333e-01, -1.79946667e-01,  6.04450000e-02,  2.40360000e-01,\n",
       "       -4.67303333e-01,  2.68529333e-01,  4.14836667e-01, -3.92226667e-01,\n",
       "       -2.74385333e-01, -4.94236667e-01,  1.94183333e-01, -6.50513333e-01,\n",
       "       -4.99481667e-01, -4.84916667e-01,  4.89716667e-01, -6.34323333e-01,\n",
       "       -6.04670000e-02, -1.27543333e+00,  1.34141667e-01, -3.95855667e-01,\n",
       "        4.24430000e-01,  6.67846667e-01, -8.45576667e-01, -2.11920000e+00,\n",
       "        1.87880333e-01,  4.96170000e-01,  1.47326667e+00,  2.34058667e-01,\n",
       "        2.56493333e-01,  1.02611000e+00, -1.20180000e+00, -1.13546567e-01,\n",
       "        5.93000000e-01, -2.77194333e-01,  4.82006667e-01,  4.93496667e-01,\n",
       "       -3.89413333e-01, -2.53713333e-01,  1.62766667e-01, -2.29796667e-01,\n",
       "        3.69513333e-01, -2.86346667e-01,  4.20193333e-01,  2.35760333e-01,\n",
       "        2.07302000e-01,  1.00535333e-01, -3.75610000e-01, -1.11193333e-01,\n",
       "        3.77929000e-01, -5.51790000e-01, -4.14616667e-01, -5.11096667e-02,\n",
       "       -1.13680667e+00,  1.24230000e-02, -2.72082667e-01, -2.53194000e-01,\n",
       "       -6.20466667e-01, -5.29950000e-01, -6.65143333e-02, -2.05833333e-01,\n",
       "        3.81217333e-01,  2.26916667e-01, -4.73783333e-01,  1.64713333e-01,\n",
       "       -2.56226667e-01, -4.80956667e-01,  3.74092667e-01,  2.81383333e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vec('i am fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['vec']=df['content'].apply(lambda x : get_vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df['vec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39137,), (39137, 3), (100,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, df.shape, X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-0.581242  ,  0.042994  ,  0.121104  ,  0.0439568 , -0.355036  ,\n",
       "        0.12429   ,  0.326738  ,  0.2518992 , -0.0173924 , -0.053602  ,\n",
       "        0.062684  ,  0.01143   ,  0.0532202 ,  0.352504  ,  0.284048  ,\n",
       "       -0.03947   , -0.360482  ,  0.022346  , -0.019428  , -0.3631894 ,\n",
       "        0.097664  ,  0.22835969, -0.240907  ,  0.048901  ,  0.15085572,\n",
       "        0.418112  ,  0.0587    ,  0.120008  ,  0.0225796 , -0.2389288 ,\n",
       "        0.26389   ,  0.1256104 ,  0.129434  , -0.1706286 , -0.10422232,\n",
       "        0.214136  ,  0.227188  ,  0.0200948 ,  0.3705206 , -0.2368624 ,\n",
       "        0.117676  , -0.0555212 , -0.0500824 , -0.457792  , -0.175     ,\n",
       "        0.0795702 , -0.274696  ,  0.1872344 ,  0.0332602 ,  0.0315022 ,\n",
       "       -0.3070098 , -0.242322  , -0.05436   ,  0.369502  , -0.1685466 ,\n",
       "       -0.9245676 ,  0.07679   ,  0.3169728 ,  0.42086094,  0.1345678 ,\n",
       "       -0.015248  , -0.070392  , -0.35235   , -0.109886  ,  0.144454  ,\n",
       "        0.39696   ,  0.333958  , -0.258178  ,  0.023776  , -0.12841   ,\n",
       "       -0.498434  ,  0.1834556 ,  0.067484  , -0.0142112 ,  0.221792  ,\n",
       "        0.033864  ,  0.0435856 , -0.21687   ,  0.1773766 , -0.016952  ,\n",
       "        0.0864364 , -0.209326  , -0.06603   , -0.0766656 , -0.382312  ,\n",
       "       -0.072771  ,  0.210228  , -0.250724  , -0.412346  ,  0.121742  ,\n",
       "       -0.3208498 ,  0.0093362 ,  0.0314358 ,  0.090972  ,  0.2894262 ,\n",
       "       -0.141172  ,  0.2282816 , -0.2118982 ,  0.3258368 , -0.035352  ]),\n",
       "       array([-0.05209733, -0.01141   , -0.20446667, -0.07894333,  0.00544733,\n",
       "        0.423972  , -0.10382   ,  0.46320667, -0.35881667,  0.08112533,\n",
       "       -0.21344333,  0.28236667,  0.184932  , -0.03707   , -0.11139667,\n",
       "       -0.29795   ,  0.14258   , -0.282468  , -0.42063   ,  0.049     ,\n",
       "        0.17872   , -0.38430333,  0.06027533,  0.37134   ,  0.19769667,\n",
       "       -0.124449  , -0.22939867,  0.38667333,  0.190217  ,  0.23754   ,\n",
       "        0.02054   , -0.32692333, -0.04545333,  0.26015333, -0.28050337,\n",
       "        0.08654333,  0.12564267,  0.111944  , -0.08476467, -0.02325667,\n",
       "       -0.14442   , -0.26870333,  0.39238333, -0.04190433, -0.0647    ,\n",
       "       -0.25253   , -0.23404333,  0.00532   ,  0.19303333, -0.62943333,\n",
       "        0.35736667, -0.34796333,  0.47053   ,  0.401404  , -0.37069333,\n",
       "       -1.26256667, -0.58479333,  0.21177   ,  1.14766667,  0.60542333,\n",
       "       -0.25765667,  0.26842333,  0.21146   , -0.37305333, -0.22444667,\n",
       "       -0.170129  , -0.0203311 ,  0.36085533, -0.17097   , -0.13178333,\n",
       "       -0.35952   , -0.47299333, -0.193973  , -0.37091   ,  0.14521967,\n",
       "        0.40118   ,  0.221723  ,  0.05387333, -0.4857    , -0.13875667,\n",
       "        0.42084333,  0.0883    ,  0.34203333, -0.22575   , -0.54843333,\n",
       "       -0.32664333,  0.019914  ,  0.13522333, -0.02973333, -0.10350233,\n",
       "        0.49584   , -0.22865667,  0.06256   ,  0.64127667, -0.72123667,\n",
       "        0.07701667,  0.20368667,  0.042191  ,  0.32959333,  0.10322   ]),\n",
       "       array([ 0.082222  ,  0.15166375,  0.04528   , -0.34479525, -0.068905  ,\n",
       "        0.052745  , -0.41164525, -0.0051975 ,  0.228249  , -0.2531225 ,\n",
       "        0.2080055 ,  0.2540025 ,  0.4067685 ,  0.09159875,  0.0634875 ,\n",
       "       -0.39922375,  0.151705  ,  0.091075  , -0.60212   ,  0.21726   ,\n",
       "        0.289725  , -0.03482325, -0.011226  , -0.27781535,  0.153048  ,\n",
       "       -0.00605925, -0.35949   , -0.74063   ,  0.4313825 , -0.11568425,\n",
       "       -0.10518825,  0.6434275 ,  0.28067875,  0.16687742,  0.06514625,\n",
       "        0.29176775,  0.21202125, -0.2103105 ,  0.271635  , -0.5321725 ,\n",
       "       -0.2956075 , -0.2287375 ,  0.29013   , -0.5908475 , -0.3175325 ,\n",
       "        0.14836725, -0.2172915 ,  0.149071  ,  0.222644  , -1.1142075 ,\n",
       "       -0.23538485, -0.09958675,  0.3052575 ,  0.88177   ,  0.0129685 ,\n",
       "       -1.795185  , -0.3110355 ,  0.29413975,  1.2670125 ,  0.311585  ,\n",
       "       -0.00928675,  0.80032   , -0.5600555 , -0.15269375,  0.6077    ,\n",
       "        0.22174475,  0.644965  ,  0.7280025 , -0.028755  ,  0.0841425 ,\n",
       "       -0.0338525 , -0.144488  , -0.22562   , -0.56662825, -0.1617625 ,\n",
       "        0.26495   , -0.1254675 ,  0.07211025, -0.128335  , -0.12341025,\n",
       "        0.411835  ,  0.057015  , -0.23042   , -0.31507375, -1.1406325 ,\n",
       "       -0.370695  , -0.038023  ,  0.093245  , -0.1525875 , -0.2270925 ,\n",
       "        0.039658  , -0.15505175,  0.478359  , -0.0467375 , -0.591705  ,\n",
       "       -0.06367   , -0.02549575, -0.2202075 , -0.04702288,  0.12107875]),\n",
       "       ...,\n",
       "       array([ 0.19080378,  0.37000211,  0.20402289, -0.26521   , -0.43091364,\n",
       "        0.42655952,  0.01988556,  0.49644189, -0.07889111, -0.17825722,\n",
       "       -0.02485111,  0.25198333,  0.26677889,  0.25105489,  0.08873667,\n",
       "       -0.09270878,  0.15348578,  0.00751711, -0.19725217,  0.47099956,\n",
       "        0.33815889,  0.17529211, -0.01141641,  0.16358778,  0.410787  ,\n",
       "        0.54658667, -0.66088   , -0.55458933,  0.24210411,  0.16052833,\n",
       "       -0.04341367,  0.26136778,  0.59186067,  0.10217089, -0.02946433,\n",
       "        0.19354111, -0.22140222,  0.23993733,  0.59729889, -0.14304611,\n",
       "       -0.37639844, -0.07793422,  0.36723044, -0.20548836, -0.09418422,\n",
       "       -0.01319189, -0.12012311, -0.11944633,  0.22456078, -0.44626111,\n",
       "       -0.14305967, -0.31858667,  0.59069889,  0.95701889, -0.39228411,\n",
       "       -1.80621309, -0.17858156,  0.36052078,  1.10681501,  0.451112  ,\n",
       "        0.07754433,  0.73475567, -0.32919478, -0.24467733,  0.49902444,\n",
       "        0.21028111,  0.59152111,  0.11910311, -0.05253011, -0.16979033,\n",
       "        0.14903733, -0.15247678,  0.04277   , -0.25130456,  0.07977067,\n",
       "        0.47513433, -0.01087544, -0.35909711, -0.51704811, -0.28808378,\n",
       "        0.13390856,  0.05459956,  0.03395033, -0.00491578, -1.24917889,\n",
       "       -0.43094222, -0.39957211, -0.04661411, -0.22947978, -0.43647444,\n",
       "        0.19777   ,  0.05972278,  0.33100089,  0.08959794, -0.62725678,\n",
       "       -0.22041322, -0.04696244, -0.21550556,  0.01523644,  0.10996333]),\n",
       "       array([-0.10549633,  0.0549915 ,  0.32400158, -0.14083433,  0.10481483,\n",
       "        0.05134708, -0.07591933,  0.22557708,  0.1814275 , -0.02231667,\n",
       "        0.19076058, -0.04859468,  0.00793892,  0.249056  ,  0.28240108,\n",
       "        0.18365383,  0.19372658,  0.14546317, -0.19240958,  0.43306825,\n",
       "        0.63868375,  0.03669083, -0.00454833,  0.1882065 ,  0.3416195 ,\n",
       "        0.13501325,  0.17055358, -0.10204008,  0.20237458,  0.00280292,\n",
       "       -0.11885742,  0.2417675 ,  0.3084175 ,  0.28662683,  0.06304383,\n",
       "        0.07856525, -0.0178015 , -0.05989342, -0.04569242, -0.46069667,\n",
       "        0.08223055,  0.13632475, -0.00684867,  0.08278642,  0.02690683,\n",
       "       -0.12601525, -0.10476792, -0.05598325,  0.2037775 , -0.18123617,\n",
       "       -0.31583867,  0.19393042, -0.00677867,  0.126955  , -0.21193792,\n",
       "       -1.35749258, -0.11218208,  0.34229983,  0.78679083,  0.14643933,\n",
       "       -0.25849733,  0.39145792, -0.19311737,  0.08191583,  0.37835124,\n",
       "        0.0726125 ,  0.20891481,  0.13622067, -0.10421367, -0.12108675,\n",
       "        0.06603475,  0.149351  , -0.11622   , -0.18806183,  0.07901525,\n",
       "        0.19743148, -0.07851517, -0.082416  , -0.07701748, -0.172068  ,\n",
       "        0.20621958, -0.19452967, -0.01727583, -0.021528  , -0.660034  ,\n",
       "        0.04254442,  0.01108928, -0.24349417,  0.05876083, -0.01361908,\n",
       "        0.11859358,  0.13245383, -0.07315   , -0.09338583, -0.14586217,\n",
       "       -0.12707508, -0.30455883, -0.30256775,  0.228846  ,  0.022579  ]),\n",
       "       array([ 0.01271055,  0.15236182,  0.41993482,  0.13220545, -0.05011364,\n",
       "       -0.15053036, -0.10963045,  0.14125609, -0.20074391,  0.17627772,\n",
       "       -0.02514727,  0.04236173,  0.09294645,  0.08156545,  0.015597  ,\n",
       "        0.15776509, -0.01817636, -0.11500391, -0.27849136, -0.16353479,\n",
       "        0.58025564, -0.14212536, -0.24338042,  0.27133718,  0.19086126,\n",
       "        0.11959427, -0.17644209,  0.13112182,  0.13260013,  0.16924291,\n",
       "       -0.19846518,  0.22087027, -0.22750818,  0.45450709, -0.10193091,\n",
       "        0.10053518,  0.15653165, -0.32638107, -0.031276  , -0.13522091,\n",
       "       -0.10010455, -0.29265   ,  0.00462455, -0.07493309,  0.07138364,\n",
       "       -0.14332264,  0.21187373,  0.02260736,  0.02629564, -0.26218009,\n",
       "       -0.04145827, -0.09727564,  0.05366818,  0.27732727, -0.1918656 ,\n",
       "       -1.04890718, -0.18863655,  0.11377618,  0.73523727,  0.390068  ,\n",
       "       -0.53235745,  0.30591091, -0.22742936,  0.20959136, -0.10158227,\n",
       "        0.34263645, -0.18655355,  0.37195709, -0.022643  ,  0.29909718,\n",
       "       -0.23355891, -0.36345891, -0.09089982, -0.14157836,  0.00365418,\n",
       "        0.17616182,  0.17349973,  0.19256609, -0.53710118,  0.077757  ,\n",
       "        0.31631418, -0.05936531, -0.01052309, -0.02817409, -0.49371591,\n",
       "        0.06935764, -0.3349626 ,  0.26772636, -0.00130536,  0.02235973,\n",
       "        0.15599455, -0.00675432,  0.40846455, -0.03106786, -0.17601727,\n",
       "        0.04714645, -0.01342927,  0.09584455,  0.22957427, -0.23362958])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "\n",
    "# now this is an array( of size (39173,) )  of arrays ( size (100,))\n",
    "# in other words, there are 39173 rows in the dataframe having a vector of size 100.\n",
    "# It is required to make all these vector value to be distributed in 100 columns seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3913700,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by concatenating the array, all values of vector will be flattened in one single dimensional array.\n",
    "np.concatenate(X, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now having 3917300 values in one row, will reshape( restructure ) it into 100 columns\n",
    "X = np.concatenate(X, axis=0)\n",
    "X = X.reshape(-1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39137, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# this would be the input variable to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39137,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# this would be the output variable to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is mulit class classifier\n",
    "clf = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    1    2    1    1   16    0    1    0   14]\n",
      " [   0    0    0    0    2    0    1   18    0    2    0   36]\n",
      " [   0    0    0    0   31    0   14  126    0    5    0   74]\n",
      " [   0    0    0    0  138    0   30  249    0   16    0  153]\n",
      " [   0    0    0    1  515    2  139  691    1   38    1  331]\n",
      " [   0    0    0    0   12   28    4  124    0   29    1  238]\n",
      " [   0    0    0    1  239    2  430  368    0   22    0  206]\n",
      " [   0    1    1    3  267   17  119 1573    3   93    1  766]\n",
      " [   0    0    0    0   72    0   22  217    2   10    0  181]\n",
      " [   0    1    0    0   97   14   64  496    0  218    0  814]\n",
      " [   0    0    0    1   92    2   50  312    1   24    0  238]\n",
      " [   0    1    0    0  138   22   89  959    0  168    1 1412]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        36\n",
      "     boredom       0.00      0.00      0.00        59\n",
      "  enthusiasm       0.00      0.00      0.00       250\n",
      "         fun       0.00      0.00      0.00       586\n",
      "   happiness       0.32      0.30      0.31      1719\n",
      "        hate       0.32      0.06      0.11       436\n",
      "        love       0.45      0.34      0.39      1268\n",
      "     neutral       0.31      0.55      0.39      2844\n",
      "      relief       0.29      0.00      0.01       504\n",
      "     sadness       0.35      0.13      0.19      1704\n",
      "    surprise       0.00      0.00      0.00       720\n",
      "       worry       0.32      0.51      0.39      2790\n",
      "\n",
      "   micro avg       0.32      0.32      0.32     12916\n",
      "   macro avg       0.20      0.16      0.15     12916\n",
      "weighted avg       0.29      0.32      0.28     12916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8619\n",
       "worry         8453\n",
       "happiness     5208\n",
       "sadness       5162\n",
       "love          3842\n",
       "surprise      2182\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1321\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nullifying the imbalance dataset via weight class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(df['sentiment']),df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.64924242, 18.22020484,  4.29699166,  1.83638326,  0.62623208,\n",
       "        2.46889982,  0.84888513,  0.3783985 ,  2.13723242,  0.6318126 ,\n",
       "        1.49469141,  0.38582949])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label=np.unique(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 29.649242424242424,\n",
       " 'boredom': 18.220204841713223,\n",
       " 'enthusiasm': 4.296991655687308,\n",
       " 'fun': 1.8363832582582582,\n",
       " 'happiness': 0.6262320788530465,\n",
       " 'hate': 2.4688998233661366,\n",
       " 'love': 0.8488851292729481,\n",
       " 'neutral': 0.37839849943922343,\n",
       " 'relief': 2.1372324159021407,\n",
       " 'sadness': 0.6318126049334883,\n",
       " 'surprise': 1.4946914146043386,\n",
       " 'worry': 0.38582948854450094}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [{l:class_weights[i]} for i,l in enumerate(class_label)]\n",
    "\n",
    "class_weight_d={class_label[i]:class_weights[i] for i in range(len(class_label))}\n",
    "class_weight_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0,\n",
       "          class_weight={'anger': 29.649242424242424, 'boredom': 18.220204841713223, 'enthusiasm': 4.296991655687308, 'fun': 1.8363832582582582, 'happiness': 0.6262320788530465, 'hate': 2.4688998233661366, 'love': 0.8488851292729481, 'neutral': 0.37839849943922343, 'relief': 2.1372324159021407, 'sadness': 0.6318126049334883, 'surprise': 1.4946914146043386, 'worry': 0.38582948854450094},\n",
       "          dual=False, fit_intercept=True, intercept_scaling=1,\n",
       "          max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "          random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression( class_weight=class_weight_d, multi_class='auto')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.08      0.01        36\n",
      "     boredom       0.02      0.25      0.03        59\n",
      "  enthusiasm       0.04      0.09      0.06       250\n",
      "         fun       0.09      0.12      0.10       586\n",
      "   happiness       0.33      0.27      0.30      1719\n",
      "        hate       0.17      0.31      0.22       436\n",
      "        love       0.37      0.43      0.40      1268\n",
      "     neutral       0.34      0.26      0.30      2844\n",
      "      relief       0.12      0.16      0.14       504\n",
      "     sadness       0.32      0.20      0.25      1704\n",
      "    surprise       0.10      0.06      0.08       720\n",
      "       worry       0.39      0.23      0.29      2790\n",
      "\n",
      "   micro avg       0.24      0.24      0.24     12916\n",
      "   macro avg       0.19      0.21      0.18     12916\n",
      "weighted avg       0.30      0.24      0.26     12916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print( classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3   2   1   3   3   3   2   8   0   1   0  10]\n",
      " [  3  15   1   2   2   8   3   7   5   5   1   7]\n",
      " [ 20  15  23  17  35   5  21  58   6  10   9  31]\n",
      " [ 40  30  36  71 107  18  55 100  22  29  31  47]\n",
      " [ 85  78  69 152 457  39 238 260 123  66  74  78]\n",
      " [ 51  34  10  16  12 137   7  37  16  42  17  57]\n",
      " [ 35  39  41  79 185  29 548 121  56  50  29  56]\n",
      " [235 239 139 189 242 147 211 743 154 157 107 281]\n",
      " [ 45  40  27  23  54  24  46  79  82  20  14  50]\n",
      " [137 134  52  73  88 138 110 204  74 347  44 303]\n",
      " [ 42  45  35  51  68  45  83 133  34  47  45  92]\n",
      " [239 229 108 120 120 212 172 417 112 324  90 647]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with SVM\n",
    "\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = LinearSVC(class_weight=class_weight_d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0,\n",
       "     class_weight={'anger': 29.649242424242424, 'boredom': 18.220204841713223, 'enthusiasm': 4.296991655687308, 'fun': 1.8363832582582582, 'happiness': 0.6262320788530465, 'hate': 2.4688998233661366, 'love': 0.8488851292729481, 'neutral': 0.37839849943922343, 'relief': 2.1372324159021407, 'sadness': 0.6318126049334883, 'surprise': 1.4946914146043386, 'worry': 0.38582948854450094},\n",
       "     dual=True, fit_intercept=True, intercept_scaling=1,\n",
       "     loss='squared_hinge', max_iter=1000, multi_class='ovr', penalty='l2',\n",
       "     random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   2   1   3   2   4   3   8   0   1   0   8]\n",
      " [  5  17   0   1   3  11   3   6   4   4   1   4]\n",
      " [ 20  24  17  14  38  17  31  49   6   8   4  22]\n",
      " [ 58  43  18  48 114  40  88  87  14  23   9  44]\n",
      " [104 121  41 116 447  77 348 214  89  56  37  69]\n",
      " [ 53  42   5  15  11 165  12  28  12  36   4  53]\n",
      " [ 49  59  23  51 182  40 619  97  35  40  16  57]\n",
      " [272 308 107 158 262 234 288 628 124 147  60 256]\n",
      " [ 44  51  16  20  67  36  61  71  66  19  10  43]\n",
      " [141 174  32  49  98 212 176 159  48 320  26 269]\n",
      " [ 50  61  23  40  76  70 103 126  25  43  20  83]\n",
      " [265 293  74  86 149 315 245 353  79 296  42 593]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.11      0.01        36\n",
      "     boredom       0.01      0.29      0.03        59\n",
      "  enthusiasm       0.05      0.07      0.06       250\n",
      "         fun       0.08      0.08      0.08       586\n",
      "   happiness       0.31      0.26      0.28      1719\n",
      "        hate       0.14      0.38      0.20       436\n",
      "        love       0.31      0.49      0.38      1268\n",
      "     neutral       0.34      0.22      0.27      2844\n",
      "      relief       0.13      0.13      0.13       504\n",
      "     sadness       0.32      0.19      0.24      1704\n",
      "    surprise       0.09      0.03      0.04       720\n",
      "       worry       0.40      0.21      0.28      2790\n",
      "\n",
      "   micro avg       0.23      0.23      0.23     12916\n",
      "   macro avg       0.18      0.20      0.17     12916\n",
      "weighted avg       0.29      0.23      0.24     12916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
