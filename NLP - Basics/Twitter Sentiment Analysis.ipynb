{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter sentiment analysis\n",
    "\n",
    "Date - 12th Oct 2020\n",
    "\n",
    "- Data - 'twitterdata.txt' \n",
    "     - There are 30 thousands tweets with their corresponding sentiments.\n",
    "     - Now our model will learn from those 30,000 tweets and predicts the sentiments for forthcoming tweets in future.\n",
    "     - Model will be evaluated on the basis of below parameters\n",
    "         - confusion matrix\n",
    "         - classification matrix\n",
    "     - model being used \n",
    "         - SVM\n",
    "         - logistic regression\n",
    "   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitterdata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitts</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robbiebronniman Sounds like a great night.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Damn the person who stolde my wallet !!!!!  Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greetings from the piano bench  (photo) http:/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@drewryanscott i love it!! i love you!! haha f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@kissthestars Pretty pretty pretty please, pak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              twitts  sentiment\n",
       "0       @robbiebronniman Sounds like a great night.           1\n",
       "1  Damn the person who stolde my wallet !!!!!  Ma...          1\n",
       "2  Greetings from the piano bench  (photo) http:/...          1\n",
       "3  @drewryanscott i love it!! i love you!! haha f...          1\n",
       "4  @kissthestars Pretty pretty pretty please, pak...          0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_SVMmodel(x):\n",
    "\n",
    "    X = df['twitts']\n",
    "    y = df['sentiment']\n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "    clf_l = LinearSVC()\n",
    "    clf_s = SVC()\n",
    "\n",
    "    clf_l.fit(X_train,y_train)\n",
    "    clf_s.fit(X_train,y_train)\n",
    "\n",
    "    y_pred_l = clf_l.predict(X_test)\n",
    "    y_pred_s = clf_s.predict(X_test)\n",
    "\n",
    "    print(f'Accurancy for LinearSVC {accuracy_score(y_test,y_pred_l)} and SVC {accuracy_score(y_test,y_pred_s)}')\n",
    "\n",
    "    print(f'linear - \\n{confusion_matrix(y_test,y_pred_l)}')\n",
    "    print (f'\\n\\nsvc - \\n{confusion_matrix(y_test,y_pred_s)}')\n",
    "\n",
    "\n",
    "    print(f'linear ------ \\n {classification_report(y_test,y_pred_l)}')\n",
    "    print (f'svc ------ \\n {classification_report(y_test,y_pred_s)}')\n",
    "    \n",
    "    # we can pass the object for further exucution also\n",
    "    return tfidf, clf_l, clf_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for LinearSVC 0.752020202020202 and SVC 0.4918181818181818\n",
      "linear - \n",
      "[[3599 1270]\n",
      " [1185 3846]]\n",
      "\n",
      "\n",
      "svc - \n",
      "[[4869    0]\n",
      " [5031    0]]\n",
      "linear ------ \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75      4869\n",
      "           1       0.75      0.76      0.76      5031\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      9900\n",
      "   macro avg       0.75      0.75      0.75      9900\n",
      "weighted avg       0.75      0.75      0.75      9900\n",
      "\n",
      "svc ------ \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      4869\n",
      "           1       0.00      0.00      0.00      5031\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      9900\n",
      "   macro avg       0.25      0.50      0.33      9900\n",
      "weighted avg       0.24      0.49      0.32      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_SVMmodel(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning \n",
    "\n",
    "- lowering all character\n",
    "- expanding the contraction\n",
    "- removing email,URL, HTML\n",
    "- removing accented char\n",
    "- lemmatization\n",
    "- spelling correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from  bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts'] = df['twitts'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "def expand_contraction(x):\n",
    "    for key,item in contraction_mapping.items():\n",
    "        x=x.replace(key,item,-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts']=df['twitts'].apply(lambda x : expand_contraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts']=df['twitts'].apply(lambda x : (re.sub('\\S+@\\S+\\.com','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "df['twitts']=df['twitts'].apply(lambda x : re.sub(regex, '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all special character , other than all alphanumeric\n",
    "df['twitts']=df['twitts'].apply(lambda x : re.sub('[^\\w ]+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts']=df['twitts'].apply(lambda x : re.sub('\\s{2,}',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts']=df['twitts'].apply(lambda x : BeautifulSoup(x,'html').get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(x):\n",
    "    x = unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return x\n",
    "df['twitts']=df['twitts'].apply(lambda x : remove_accented_chars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['twitts']= df['twitts'].apply(lambda x : ' '.join([w for w in x.split() if w not in STOP_WORDS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rootword(x):\n",
    "    doc = nlp(x)\n",
    "    x_list=[]\n",
    "    for token in doc:\n",
    "        lemma = token.lemma_\n",
    "        x_list.append(lemma)\n",
    "    return ' '.join(x_list)\n",
    "\n",
    "df['twitts'] = df['twitts'].apply(lambda x : convert_to_rootword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['twitts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### After cleaning the data , will train the model again. And will check if efficiency is increased or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy for LinearSVC 0.7226262626262626 and SVC 0.4918181818181818\n",
      "linear - \n",
      "[[3406 1463]\n",
      " [1283 3748]]\n",
      "\n",
      "\n",
      "svc - \n",
      "[[4869    0]\n",
      " [5031    0]]\n",
      "linear ------ \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      4869\n",
      "           1       0.72      0.74      0.73      5031\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      9900\n",
      "   macro avg       0.72      0.72      0.72      9900\n",
      "weighted avg       0.72      0.72      0.72      9900\n",
      "\n",
      "svc ------ \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      4869\n",
      "           1       0.00      0.00      0.00      5031\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      9900\n",
      "   macro avg       0.25      0.50      0.33      9900\n",
      "weighted avg       0.24      0.49      0.32      9900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mein Pc\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0),\n",
       " SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "   kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_SVMmodel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
